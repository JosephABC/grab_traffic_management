{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grab_TrafficManagement_Model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "euY3kQT49Sve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input Files\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from multiprocessing import Pool, Manager\n",
        "import random\n",
        "\n",
        "#Input address to test dataset csv file\n",
        "test_df = pd.read_csv(\"gdrive/My Drive/GrabAI/training.csv\")\n",
        "#Address to csv files with geohashes (came in same directory as this jupyter notebook)\n",
        "geohash_df = pd.read_csv(\"gdrive/My Drive/GrabAI/geohash_df.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytdlmPVi9gu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get last data set values leading up to T\n",
        "max_day = np.amax(test_df['day'])\n",
        "test_df = test_df[test_df['day'] >= max_day - 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFfX44kD9jTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert day and Time stamp to mins\n",
        "\n",
        "tic = time.time()\n",
        "def parallelize_dataframe_time(df, func):\n",
        "  fragment_array = np.array_split(df, 20)\n",
        "  pool = Pool(20)\n",
        "  df = pd.concat(pool.map(func, fragment_array))\n",
        "  pool.close()\n",
        "  pool.join()\n",
        "  return df\n",
        "\n",
        "def get_time(x):\n",
        "  hour, minute = x[1].split(':')\n",
        "  return int(x[0]-1)*24*60 + int(hour)*60 + int(minute)\n",
        "\n",
        "def test_func_time(data):\n",
        "  fragment_id = random.randint(0,999)\n",
        "  print('Running: {}'.format(fragment_id))\n",
        "  data['time'] = data[['day','timestamp']].apply(get_time, axis=1)\n",
        "  print('Done: {}'.format(fragment_id))\n",
        "  return data\n",
        "\n",
        "test_df = parallelize_dataframe_time(test_df, test_func_time)\n",
        "toc = time.time()\n",
        "print(toc - tic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA_HwDko9nop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get demands for last 97 time values\n",
        "import itertools\n",
        "\n",
        "tic = time.time()\n",
        "max_time = np.amax(test_df['time'])\n",
        "time_list = np.zeros(97)\n",
        "for i in range(0,97):\n",
        "  time_list[i] = max_time - i * 15\n",
        "\n",
        "unique_geohash_list = geohash_df.values.tolist()\n",
        "n_unique_geohash = len(unique_geohash_list)\n",
        "unique_geohash_list  = list(itertools.chain(*unique_geohash_list))\n",
        "geohash_dict = {unique_geohash_list[i]:i for i in range(n_unique_geohash)}\n",
        "demand_df = pd.DataFrame(time_list, columns=['time'])\n",
        "processes = 40\n",
        "\n",
        "def parallelize_dataframe(df, func):\n",
        "  fragment_array = np.array_split(df, processes)\n",
        "  pool = Pool(processes)\n",
        "  df = pd.concat(pool.map(func, fragment_array))\n",
        "  pool.close()\n",
        "  pool.join()\n",
        "  return df\n",
        "\n",
        "def get_demand_snapshot(x):\n",
        "  demand_snapshot = np.zeros(n_unique_geohash)\n",
        "  time_df = test_df['time'] == x\n",
        "  df_snapshot = test_df[time_df]\n",
        "  for _, row in df_snapshot.iterrows():\n",
        "    demand_snapshot[geohash_dict[row['geohash6']]] = row['demand']\n",
        "  return demand_snapshot\n",
        "\n",
        "def test_func_demand(data):\n",
        "  fragment_id = random.randint(0,999)\n",
        "  print('Running: {}'.format(fragment_id))\n",
        "  data['demand_snapshot'] = data['time'].apply(get_demand_snapshot)\n",
        "  n_done[0] += 1\n",
        "  print('Done: {}, {}/{}'.format(fragment_id, n_done[0], processes))\n",
        "  return data\n",
        "\n",
        "n_done = Manager().list(range(1))\n",
        "n_done[0] = 0\n",
        "demand_df = parallelize_dataframe(demand_df, test_func_demand)\n",
        "\n",
        "\n",
        "toc = time.time()\n",
        "print(toc - tic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQvpSrCz9rqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create array for model prediction\n",
        "demand_df.sort_values(by=['time'], inplace=True)\n",
        "data_list= demand_df['demand_snapshot'].values.tolist()\n",
        "data = pd.DataFrame(data_list)\n",
        "test_X = data.values\n",
        "test_X = test_X.reshape(1,test_X.shape[0],test_X.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VfZ8wac9tfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prediction Using Model\n",
        "import keras\n",
        "\n",
        "#Input Path to model (Came in the same directory as this jupyter notebook)\n",
        "new_model = keras.models.load_model('gdrive/My Drive/GrabAI/model_30_96_25.h5')\n",
        "yhat = new_model.predict(test_X)\n",
        "names = list()\n",
        "predictions_df = pd.DataFrame()\n",
        "predictions_df['geohash'] = unique_geohash_list\n",
        "for i in range(0,5):\n",
        "  start = n_unique_geohash*i\n",
        "  end = (i+1)*n_unique_geohash\n",
        "  demand = yhat[0][start:end]\n",
        "  predictions_df['T + {}'.format(i+1)] = demand"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhwRaTKhsRol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}